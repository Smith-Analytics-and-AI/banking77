{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_counts(data, text_col = \"tweet_text\", min_df=2, ngrams=(1,1)):   \n",
    "    \n",
    "    # Quick and dirty counter of terms and tokens (before we whittle down later)\n",
    "    results = Counter()\n",
    "    data_pre = data\n",
    "    data_pre.str.split().apply(results.update)\n",
    "    \n",
    "    n_docs = data.shape[0]\n",
    "    n_terms = len(results)\n",
    "    n_tokens = sum(results.values())\n",
    "    \n",
    "    print('Number of documents: {}'.format(n_docs))\n",
    "    print('Number of word forms (terms): {}'.format(n_terms))\n",
    "    print('Number of words (tokens): {}'.format(n_tokens))\n",
    "    print('Mean words per document: {:.1f}'.format(n_tokens / n_docs))\n",
    "    print('Mean term occurance: {:.1f}'.format(np.mean(list(results.values()))))\n",
    "    for m in [1, 5, 10, 100]:\n",
    "        vs = {k:v for (k, v) in results.items() if v <= m}\n",
    "        print('Number (Pct) of terms occuring <= {}: {} ({:.1f})'.format(m, len(vs), 100*len(vs)/n_terms))\n",
    "        \n",
    "    \n",
    "    # We override the token_pattern in order to keep @signs and #hashtags\n",
    "    vec = CountVectorizer(      #preprocessor=preprocessor,\n",
    "                                token_pattern = '[a-zA-Z0-9@#]+',\n",
    "                                stop_words=\"english\",\n",
    "                                lowercase=True,\n",
    "                                min_df=min_df,\n",
    "                                ngram_range=ngrams,\n",
    "                                max_features=10000)\n",
    "    \n",
    "    bow = vec.fit_transform(data)\n",
    "    vocab = vec.get_feature_names()\n",
    "    tdm = pd.DataFrame(bow.toarray(), columns=vocab)\n",
    "        \n",
    "    \n",
    "    n_tokens = sum(tdm.sum())\n",
    "    n_docs = tdm.shape[0]\n",
    "    phrases = list(tdm.columns)\n",
    "    counts = pd.DataFrame(data={'Phrase': phrases, \n",
    "                                'Characters': [len(x) for x in phrases],\n",
    "                                'Terms': [x.count(' ')+1 for x in phrases],\n",
    "                                'Count': tdm.sum(),\n",
    "                                'Count Pct': tdm.sum() / n_tokens,\n",
    "                                'Docs': tdm.astype(bool).sum(),\n",
    "                                'Docs Pct': tdm.astype(bool).sum() / n_docs,\n",
    "                          })\n",
    "    \n",
    "    counts = counts.sort_values(by=['Count'], ascending=False)\n",
    "    \n",
    "    print('Top {} words:'.format(num_words_to_print))\n",
    "    print(counts.head(num_words_to_print))\n",
    "    print('\\nBottom {} words:'.format(num_words_to_print))\n",
    "    print(counts.tail(num_words_to_print))\n",
    "    \n",
    "    \n",
    "    return tdm, vocab, counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 10003\n",
      "Number of word forms (terms): 4518\n",
      "Number of words (tokens): 119530\n",
      "Mean words per document: 11.9\n",
      "Mean term occurance: 26.5\n",
      "Number (Pct) of terms occuring <= 1: 1940 (42.9)\n",
      "Number (Pct) of terms occuring <= 5: 3200 (70.8)\n",
      "Number (Pct) of terms occuring <= 10: 3623 (80.2)\n",
      "Number (Pct) of terms occuring <= 100: 4341 (96.1)\n",
      "Top 25 words:\n",
      "                  Phrase  Characters  Terms  Count  Count Pct  Docs  Docs Pct\n",
      "card                card           4      1   2682   0.044147  2578  0.257723\n",
      "t                      t           1      1   1582   0.026041  1521  0.152054\n",
      "account          account           7      1   1352   0.022255  1288  0.128761\n",
      "money              money           5      1   1133   0.018650  1068  0.106768\n",
      "transfer        transfer           8      1   1084   0.017843  1025  0.102469\n",
      "payment          payment           7      1    751   0.012362   709  0.070879\n",
      "need                need           4      1    698   0.011490   675  0.067480\n",
      "cash                cash           4      1    691   0.011374   676  0.067580\n",
      "exchange        exchange           8      1    549   0.009037   536  0.053584\n",
      "charged          charged           7      1    529   0.008708   511  0.051085\n",
      "s                      s           1      1    511   0.008411   475  0.047486\n",
      "atm                  atm           3      1    482   0.007934   466  0.046586\n",
      "app                  app           3      1    469   0.007720   468  0.046786\n",
      "fee                  fee           3      1    458   0.007539   442  0.044187\n",
      "use                  use           3      1    427   0.007029   422  0.042187\n",
      "pending          pending           7      1    424   0.006979   409  0.040888\n",
      "did                  did           3      1    388   0.006387   381  0.038089\n",
      "help                help           4      1    369   0.006074   366  0.036589\n",
      "long                long           4      1    362   0.005959   354  0.035389\n",
      "transaction  transaction          11      1    354   0.005827   345  0.034490\n",
      "pin                  pin           3      1    343   0.005646   335  0.033490\n",
      "new                  new           3      1    334   0.005498   324  0.032390\n",
      "rate                rate           4      1    333   0.005481   316  0.031591\n",
      "make                make           4      1    322   0.005300   313  0.031291\n",
      "didn                didn           4      1    316   0.005202   314  0.031391\n",
      "\n",
      "Bottom 25 words:\n",
      "                                                      Phrase  Characters  \\\n",
      "use account identity                    use account identity          20   \n",
      "used atm                                            used atm           8   \n",
      "card doesn t                                    card doesn t          12   \n",
      "did payment                                      did payment          11   \n",
      "t virtual card                                t virtual card          14   \n",
      "t virtual                                          t virtual           9   \n",
      "t use card                                        t use card          10   \n",
      "right away                                        right away          10   \n",
      "russian                                              russian           7   \n",
      "frequent                                            frequent           8   \n",
      "forever                                              forever           7   \n",
      "sent payment                                    sent payment          12   \n",
      "did cash                                            did cash           8   \n",
      "showing statement                          showing statement          17   \n",
      "account isn t                                  account isn t          13   \n",
      "shows app                                          shows app           9   \n",
      "account isn                                      account isn          11   \n",
      "states                                                states           6   \n",
      "fee transferring                            fee transferring          16   \n",
      "steps need                                        steps need          10   \n",
      "account identity verification  account identity verification          29   \n",
      "account identity                            account identity          16   \n",
      "t changed                                          t changed           9   \n",
      "t updated                                          t updated           9   \n",
      "fraudulent                                        fraudulent          10   \n",
      "\n",
      "                               Terms  Count  Count Pct  Docs  Docs Pct  \n",
      "use account identity               3     10   0.000165    10     0.001  \n",
      "used atm                           2     10   0.000165    10     0.001  \n",
      "card doesn t                       3     10   0.000165    10     0.001  \n",
      "did payment                        2     10   0.000165    10     0.001  \n",
      "t virtual card                     3     10   0.000165    10     0.001  \n",
      "t virtual                          2     10   0.000165    10     0.001  \n",
      "t use card                         3     10   0.000165    10     0.001  \n",
      "right away                         2     10   0.000165    10     0.001  \n",
      "russian                            1     10   0.000165    10     0.001  \n",
      "frequent                           1     10   0.000165    10     0.001  \n",
      "forever                            1     10   0.000165    10     0.001  \n",
      "sent payment                       2     10   0.000165    10     0.001  \n",
      "did cash                           2     10   0.000165    10     0.001  \n",
      "showing statement                  2     10   0.000165    10     0.001  \n",
      "account isn t                      3     10   0.000165    10     0.001  \n",
      "shows app                          2     10   0.000165    10     0.001  \n",
      "account isn                        2     10   0.000165    10     0.001  \n",
      "states                             1     10   0.000165    10     0.001  \n",
      "fee transferring                   2     10   0.000165    10     0.001  \n",
      "steps need                         2     10   0.000165    10     0.001  \n",
      "account identity verification      3     10   0.000165    10     0.001  \n",
      "account identity                   2     10   0.000165    10     0.001  \n",
      "t changed                          2     10   0.000165    10     0.001  \n",
      "t updated                          2     10   0.000165    10     0.001  \n",
      "fraudulent                         1     10   0.000165    10     0.001  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('clean.csv')\n",
    "tdm, vocab, counts = find_counts(df['text'], min_df=10, ngrams=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8575\n",
      "Number of word forms (terms): 4230\n",
      "Number of words (tokens): 103776\n",
      "Mean words per document: 12.1\n",
      "Mean term occurance: 24.5\n",
      "Number (Pct) of terms occuring <= 1: 1775 (42.0)\n",
      "Number (Pct) of terms occuring <= 5: 3005 (71.0)\n",
      "Number (Pct) of terms occuring <= 10: 3389 (80.1)\n",
      "Number (Pct) of terms occuring <= 100: 4067 (96.1)\n",
      "Top 25 words:\n",
      "                  Phrase  Characters  Terms  Count  Count Pct  Docs  Docs Pct\n",
      "card                card           4      1   2227   0.043298  2133  0.248746\n",
      "t                      t           1      1   1300   0.025275  1251  0.145889\n",
      "account          account           7      1   1198   0.023292  1137  0.132595\n",
      "money              money           5      1    956   0.018587   895  0.104373\n",
      "transfer        transfer           8      1    880   0.017109   828  0.096560\n",
      "cash                cash           4      1    630   0.012249   615  0.071720\n",
      "need                need           4      1    617   0.011996   597  0.069621\n",
      "payment          payment           7      1    611   0.011879   573  0.066822\n",
      "exchange        exchange           8      1    494   0.009605   481  0.056093\n",
      "charged          charged           7      1    486   0.009449   470  0.054810\n",
      "s                      s           1      1    449   0.008730   417  0.048630\n",
      "atm                  atm           3      1    441   0.008574   426  0.049679\n",
      "app                  app           3      1    428   0.008321   427  0.049796\n",
      "fee                  fee           3      1    401   0.007796   385  0.044898\n",
      "use                  use           3      1    372   0.007233   367  0.042799\n",
      "pending          pending           7      1    358   0.006960   344  0.040117\n",
      "did                  did           3      1    330   0.006416   323  0.037668\n",
      "help                help           4      1    317   0.006163   314  0.036618\n",
      "pin                  pin           3      1    309   0.006008   301  0.035102\n",
      "transaction  transaction          11      1    297   0.005774   288  0.033586\n",
      "rate                rate           4      1    296   0.005755   279  0.032536\n",
      "long                long           4      1    288   0.005599   281  0.032770\n",
      "wrong              wrong           5      1    277   0.005386   273  0.031837\n",
      "make                make           4      1    276   0.005366   268  0.031254\n",
      "withdrawal    withdrawal          10      1    271   0.005269   265  0.030904\n",
      "\n",
      "Bottom 25 words:\n",
      "                                                Phrase  Characters  Terms  \\\n",
      "transfer uk account                transfer uk account          19      3   \n",
      "transfers free                          transfers free          14      2   \n",
      "transfers getting                    transfers getting          17      2   \n",
      "transfers getting declined  transfers getting declined          26      3   \n",
      "tried times                                tried times          11      2   \n",
      "showing statement                    showing statement          17      2   \n",
      "russian                                        russian           7      1   \n",
      "refund showing                          refund showing          14      2   \n",
      "recent transfer                        recent transfer          15      2   \n",
      "money transaction                    money transaction          17      2   \n",
      "mugged                                          mugged           6      1   \n",
      "need assistance                        need assistance          15      2   \n",
      "need order new                          need order new          14      3   \n",
      "new pin                                        new pin           7      2   \n",
      "normal                                          normal           6      1   \n",
      "atm gave                                      atm gave           8      2   \n",
      "atm didn t                                  atm didn t          10      3   \n",
      "atm didn                                      atm didn           8      2   \n",
      "pay working                                pay working          11      2   \n",
      "payment s                                    payment s           9      2   \n",
      "phone hotel                                phone hotel          11      2   \n",
      "pretty                                          pretty           6      1   \n",
      "rate cash                                    rate cash           9      2   \n",
      "receiving money                        receiving money          15      2   \n",
      "like card payment                    like card payment          17      3   \n",
      "\n",
      "                            Count  Count Pct  Docs  Docs Pct  \n",
      "transfer uk account            10   0.000194    10  0.001166  \n",
      "transfers free                 10   0.000194    10  0.001166  \n",
      "transfers getting              10   0.000194    10  0.001166  \n",
      "transfers getting declined     10   0.000194    10  0.001166  \n",
      "tried times                    10   0.000194    10  0.001166  \n",
      "showing statement              10   0.000194    10  0.001166  \n",
      "russian                        10   0.000194    10  0.001166  \n",
      "refund showing                 10   0.000194    10  0.001166  \n",
      "recent transfer                10   0.000194    10  0.001166  \n",
      "money transaction              10   0.000194    10  0.001166  \n",
      "mugged                         10   0.000194    10  0.001166  \n",
      "need assistance                10   0.000194    10  0.001166  \n",
      "need order new                 10   0.000194    10  0.001166  \n",
      "new pin                        10   0.000194    10  0.001166  \n",
      "normal                         10   0.000194    10  0.001166  \n",
      "atm gave                       10   0.000194    10  0.001166  \n",
      "atm didn t                     10   0.000194    10  0.001166  \n",
      "atm didn                       10   0.000194    10  0.001166  \n",
      "pay working                    10   0.000194    10  0.001166  \n",
      "payment s                      10   0.000194    10  0.001166  \n",
      "phone hotel                    10   0.000194    10  0.001166  \n",
      "pretty                         10   0.000194    10  0.001166  \n",
      "rate cash                      10   0.000194    10  0.001166  \n",
      "receiving money                10   0.000194    10  0.001166  \n",
      "like card payment              10   0.000194    10  0.001166  \n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('Banking77_trimmed_updatedLabels_load.csv')\n",
    "tdm, vocab, counts = find_counts(df2['text'], min_df=10, ngrams=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
